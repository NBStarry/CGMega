{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "This tutorial demonstrates how to use CGMega functions with a demo dataset (MCF7 cell line as an example). Once you are familiar with CGMegaâ€™s workflow, please replace the demo data with your own data to begin your analysis. \n",
    "\n",
    "If you just want to train the model without rebuild the dataset, skip to [Load data and Train model](#load-data-and-train-model).\n",
    "\n",
    "## How to prepare input data\n",
    "\n",
    "We recommend getting started with CGMega using the provided demo dataset. When you want to apply CGMega to your own multi-omics dataset, please refer to the following tutorials to learn how to prepare input data.\n",
    "\n",
    "Overall, the input data consists of two parts: the graph, constructed from PPI and the node feature including condensed Hi-C features, SNVs, CNVs frequencies and epigenetic densities.\n",
    "\n",
    "If you are unfamiliar with CGMega, you may start with our data used in the paper to save your time. For MCF7 cell line, K562 cell line and AML patients, the input data as well as their label information are uploaded [here](https://github.com/NBStarry/CGMega/tree/main/data). If you start with any one from these data, you can skip the step 1 about How to prepare input data. The following steps from 1.1~1.3 can be found in our source code [data_preprocess_cv.py](https://github.com/NBStarry/CGMega/tree/main/data_preprocess_cv.py).\n",
    "\n",
    "> The labels should be collected yourself if you choose analyze your own data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import default params and set constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OR4F5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SAMD11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NOC2L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KLHL17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PLEKHN1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ISG15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGRN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C1orf159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TTLL10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SDF4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gene Name\n",
       "0     OR4F5\n",
       "1    SAMD11\n",
       "2     NOC2L\n",
       "3    KLHL17\n",
       "4   PLEKHN1\n",
       "5     ISG15\n",
       "6      AGRN\n",
       "7  C1orf159\n",
       "8    TTLL10\n",
       "9      SDF4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import utils\n",
    "import config_load\n",
    "\n",
    "configs = config_load.get()\n",
    "\n",
    "DATA_DIR = configs['data_dir']\n",
    "# DATA_DIR should contain 'Breast_Cancer' to run the code. See data_preprocess_cv.get_cell_line().\n",
    "PPI = configs['ppi']\n",
    "RANDOM_SEED = configs['random_seed']\n",
    "CV_FOLDS = configs['cv_folds']\n",
    "GENE_LIST = utils.get_gene_list(rename=True)\n",
    "GENE_LIST[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hi-C data embedding\n",
    "Before SVD, the Hi-C data should go through: \n",
    "1. processing by [NeoLoopFinder](https://github.com/XiaoTaoWang/NeoLoopFinder) to remove the potential effects of structural variation; \n",
    "2. normalization using [ICE]( https://bitbucket.org/mirnylab/hiclib) correction to improve the data quality. \n",
    "> Demo data had already gone through these steps. Skip to []().\n",
    "\n",
    "If you are new to these two tools, please go through these document in advance.\n",
    "[tutorial for NeoLoopFinder (need link)](./)\n",
    "[tutorial for Hi-C normalization (need link)](./)\n",
    "\n",
    "The parameters and main functions used in NeoLoopFinder are listed as below:\n",
    "\n",
    "---\n",
    "\n",
    "Parameters:\n",
    "\n",
    "- input file format: .cool or .mcool\n",
    "- resolution: 10Kb\n",
    "- binsize: 10000\n",
    "- ploidy: 2\n",
    "- enzymes: MobI\n",
    "- genome: hg38\n",
    "\n",
    "Please choose parameters by [NeoLoopFinder](https://github.com/XiaoTaoWang/NeoLoopFinder) to suit your data. An example is available in [batch_neoloop.sh](https://github.com/NBStarry/CGMega/blob/main/data/AML_Matrix/batch_neoloop.sh)\n",
    "\n",
    "---\n",
    "\n",
    "Then we implement ICE correction following [Imakaev, Maxim et al.](https://www.nature.com/articles/nmeth.2148) and this step has beed packaged in one-line command as `content from xuxiang`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hi-C preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NumbaDeprecationWarning' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdata_preprocess_cv\u001b[39;00m \u001b[39mimport\u001b[39;00m get_hic_mat\n\u001b[1;32m      3\u001b[0m \u001b[39m# Hi-C matrix should be put into DATA_DIR first.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# Hi-C matrix should be named as \"MCF7_Adjacent_Matrix_Ice\" to run the code. See data_preprocess_cv.get_hic_mat().get_hic_dir()\u001b[39;00m\n\u001b[1;32m      5\u001b[0m hic_mat \u001b[39m=\u001b[39m get_hic_mat(data_dir\u001b[39m=\u001b[39mDATA_DIR) \u001b[39m# this could take serveral minutes (2m 11s on our computer).\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-sjtu.edu.cn/Codes/CGMega/data_preprocess_cv.py:14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmanifold\u001b[39;00m \u001b[39mimport\u001b[39;00m TSNE, Isomap, LocallyLinearEmbedding\n\u001b[1;32m     13\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, category\u001b[39m=\u001b[39mNumbaDeprecationWarning)\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mumap\u001b[39;00m \u001b[39mimport\u001b[39;00m UMAP\n\u001b[1;32m     16\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mconfig_load\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'NumbaDeprecationWarning' is not defined"
     ]
    }
   ],
   "source": [
    "from data_preprocess_cv import get_hic_mat\n",
    "\n",
    "# Hi-C matrix should be put into DATA_DIR first.\n",
    "# Hi-C matrix should be named as \"MCF7_Adjacent_Matrix_Ice\" to run the code. See data_preprocess_cv.get_hic_mat().get_hic_dir()\n",
    "hic_mat = get_hic_mat(data_dir=DATA_DIR) # this could take serveral minutes (2m 11s on our computer).\n",
    "\n",
    "hic_df = pd.DataFrame(data=hic_mat, columns=[f'HiC-{i}' for i in range(5)])\n",
    "hic_df = pd.concat([GENE_LIST, hic_df], axis=1)\n",
    "hic_df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-omics data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (16165, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene Name</th>\n",
       "      <th>ATAC-1</th>\n",
       "      <th>CTCF-1</th>\n",
       "      <th>CTCF-2</th>\n",
       "      <th>CTCF-3</th>\n",
       "      <th>H3K4me3-1</th>\n",
       "      <th>H3K4me3-2</th>\n",
       "      <th>H3K27ac-1</th>\n",
       "      <th>H3K27ac-2</th>\n",
       "      <th>Means-SNV</th>\n",
       "      <th>Means-CNV</th>\n",
       "      <th>HiC-0</th>\n",
       "      <th>HiC-1</th>\n",
       "      <th>HiC-2</th>\n",
       "      <th>HiC-3</th>\n",
       "      <th>HiC-4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OR4F5</td>\n",
       "      <td>0.529128</td>\n",
       "      <td>0.070841</td>\n",
       "      <td>0.105758</td>\n",
       "      <td>0.225933</td>\n",
       "      <td>0.130488</td>\n",
       "      <td>0.618429</td>\n",
       "      <td>0.482443</td>\n",
       "      <td>0.621274</td>\n",
       "      <td>0.487092</td>\n",
       "      <td>0.180119</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.224522</td>\n",
       "      <td>0.240360</td>\n",
       "      <td>0.480144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SAMD11</td>\n",
       "      <td>0.796776</td>\n",
       "      <td>0.489768</td>\n",
       "      <td>0.365744</td>\n",
       "      <td>0.671051</td>\n",
       "      <td>0.839078</td>\n",
       "      <td>0.884736</td>\n",
       "      <td>0.816900</td>\n",
       "      <td>0.836558</td>\n",
       "      <td>0.150033</td>\n",
       "      <td>0.177968</td>\n",
       "      <td>0.983034</td>\n",
       "      <td>0.022809</td>\n",
       "      <td>0.215827</td>\n",
       "      <td>0.232253</td>\n",
       "      <td>0.483053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NOC2L</td>\n",
       "      <td>0.840875</td>\n",
       "      <td>0.235458</td>\n",
       "      <td>0.212696</td>\n",
       "      <td>0.342695</td>\n",
       "      <td>0.854631</td>\n",
       "      <td>0.946797</td>\n",
       "      <td>0.840622</td>\n",
       "      <td>0.827042</td>\n",
       "      <td>0.454941</td>\n",
       "      <td>0.177968</td>\n",
       "      <td>0.982147</td>\n",
       "      <td>0.037410</td>\n",
       "      <td>0.187268</td>\n",
       "      <td>0.224593</td>\n",
       "      <td>0.464583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KLHL17</td>\n",
       "      <td>0.799964</td>\n",
       "      <td>0.238202</td>\n",
       "      <td>0.184042</td>\n",
       "      <td>0.433269</td>\n",
       "      <td>0.787226</td>\n",
       "      <td>0.852321</td>\n",
       "      <td>0.726881</td>\n",
       "      <td>0.777425</td>\n",
       "      <td>0.446193</td>\n",
       "      <td>0.177968</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.224522</td>\n",
       "      <td>0.240360</td>\n",
       "      <td>0.480144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PLEKHN1</td>\n",
       "      <td>0.877223</td>\n",
       "      <td>0.391312</td>\n",
       "      <td>0.305844</td>\n",
       "      <td>0.426802</td>\n",
       "      <td>0.840988</td>\n",
       "      <td>0.905411</td>\n",
       "      <td>0.919055</td>\n",
       "      <td>0.841827</td>\n",
       "      <td>0.448487</td>\n",
       "      <td>0.177968</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.224522</td>\n",
       "      <td>0.240360</td>\n",
       "      <td>0.480144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ISG15</td>\n",
       "      <td>0.858863</td>\n",
       "      <td>0.691608</td>\n",
       "      <td>0.716028</td>\n",
       "      <td>0.778756</td>\n",
       "      <td>0.885734</td>\n",
       "      <td>0.916357</td>\n",
       "      <td>0.978684</td>\n",
       "      <td>0.834207</td>\n",
       "      <td>0.391635</td>\n",
       "      <td>0.177968</td>\n",
       "      <td>0.990749</td>\n",
       "      <td>0.013589</td>\n",
       "      <td>0.217608</td>\n",
       "      <td>0.228825</td>\n",
       "      <td>0.481511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGRN</td>\n",
       "      <td>0.866120</td>\n",
       "      <td>0.497205</td>\n",
       "      <td>0.478136</td>\n",
       "      <td>0.686338</td>\n",
       "      <td>0.825454</td>\n",
       "      <td>0.889098</td>\n",
       "      <td>0.930359</td>\n",
       "      <td>0.788913</td>\n",
       "      <td>0.422046</td>\n",
       "      <td>0.179403</td>\n",
       "      <td>0.974280</td>\n",
       "      <td>0.055531</td>\n",
       "      <td>0.190371</td>\n",
       "      <td>0.218615</td>\n",
       "      <td>0.485405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C1orf159</td>\n",
       "      <td>0.899884</td>\n",
       "      <td>0.316383</td>\n",
       "      <td>0.242535</td>\n",
       "      <td>0.465516</td>\n",
       "      <td>0.844503</td>\n",
       "      <td>0.893245</td>\n",
       "      <td>0.870405</td>\n",
       "      <td>0.761551</td>\n",
       "      <td>0.255589</td>\n",
       "      <td>0.179403</td>\n",
       "      <td>0.961529</td>\n",
       "      <td>0.062132</td>\n",
       "      <td>0.185861</td>\n",
       "      <td>0.212024</td>\n",
       "      <td>0.454003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TTLL10</td>\n",
       "      <td>0.665885</td>\n",
       "      <td>0.355122</td>\n",
       "      <td>0.315340</td>\n",
       "      <td>0.436435</td>\n",
       "      <td>0.304085</td>\n",
       "      <td>0.617047</td>\n",
       "      <td>0.560824</td>\n",
       "      <td>0.671845</td>\n",
       "      <td>0.403230</td>\n",
       "      <td>0.180119</td>\n",
       "      <td>0.991588</td>\n",
       "      <td>0.010711</td>\n",
       "      <td>0.215210</td>\n",
       "      <td>0.235848</td>\n",
       "      <td>0.479124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SDF4</td>\n",
       "      <td>0.874973</td>\n",
       "      <td>0.400828</td>\n",
       "      <td>0.283395</td>\n",
       "      <td>0.513313</td>\n",
       "      <td>0.867976</td>\n",
       "      <td>0.940533</td>\n",
       "      <td>0.904143</td>\n",
       "      <td>0.823765</td>\n",
       "      <td>0.417376</td>\n",
       "      <td>0.180119</td>\n",
       "      <td>0.974903</td>\n",
       "      <td>0.039698</td>\n",
       "      <td>0.176009</td>\n",
       "      <td>0.226074</td>\n",
       "      <td>0.492445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gene Name    ATAC-1    CTCF-1    CTCF-2    CTCF-3  H3K4me3-1  H3K4me3-2  \\\n",
       "0     OR4F5  0.529128  0.070841  0.105758  0.225933   0.130488   0.618429   \n",
       "1    SAMD11  0.796776  0.489768  0.365744  0.671051   0.839078   0.884736   \n",
       "2     NOC2L  0.840875  0.235458  0.212696  0.342695   0.854631   0.946797   \n",
       "3    KLHL17  0.799964  0.238202  0.184042  0.433269   0.787226   0.852321   \n",
       "4   PLEKHN1  0.877223  0.391312  0.305844  0.426802   0.840988   0.905411   \n",
       "5     ISG15  0.858863  0.691608  0.716028  0.778756   0.885734   0.916357   \n",
       "6      AGRN  0.866120  0.497205  0.478136  0.686338   0.825454   0.889098   \n",
       "7  C1orf159  0.899884  0.316383  0.242535  0.465516   0.844503   0.893245   \n",
       "8    TTLL10  0.665885  0.355122  0.315340  0.436435   0.304085   0.617047   \n",
       "9      SDF4  0.874973  0.400828  0.283395  0.513313   0.867976   0.940533   \n",
       "\n",
       "   H3K27ac-1  H3K27ac-2  Means-SNV  Means-CNV     HiC-0     HiC-1     HiC-2  \\\n",
       "0   0.482443   0.621274   0.487092   0.180119  1.000000  0.000160  0.224522   \n",
       "1   0.816900   0.836558   0.150033   0.177968  0.983034  0.022809  0.215827   \n",
       "2   0.840622   0.827042   0.454941   0.177968  0.982147  0.037410  0.187268   \n",
       "3   0.726881   0.777425   0.446193   0.177968  1.000000  0.000160  0.224522   \n",
       "4   0.919055   0.841827   0.448487   0.177968  1.000000  0.000160  0.224522   \n",
       "5   0.978684   0.834207   0.391635   0.177968  0.990749  0.013589  0.217608   \n",
       "6   0.930359   0.788913   0.422046   0.179403  0.974280  0.055531  0.190371   \n",
       "7   0.870405   0.761551   0.255589   0.179403  0.961529  0.062132  0.185861   \n",
       "8   0.560824   0.671845   0.403230   0.180119  0.991588  0.010711  0.215210   \n",
       "9   0.904143   0.823765   0.417376   0.180119  0.974903  0.039698  0.176009   \n",
       "\n",
       "      HiC-3     HiC-4  \n",
       "0  0.240360  0.480144  \n",
       "1  0.232253  0.483053  \n",
       "2  0.224593  0.464583  \n",
       "3  0.240360  0.480144  \n",
       "4  0.240360  0.480144  \n",
       "5  0.228825  0.481511  \n",
       "6  0.218615  0.485405  \n",
       "7  0.212024  0.454003  \n",
       "8  0.235848  0.479124  \n",
       "9  0.226074  0.492445  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_preprocess_cv import get_node_feat\n",
    "\n",
    "# Node feature file should be put into DATA_DIR first, and should be named as \"MCF7-Normalized-Nodefeature-Matrix.csv\"\n",
    "node_feat, pos = get_node_feat(hic_feat=hic_mat, data_dir=DATA_DIR)\n",
    "feat_cols = ['ATAC-1','CTCF-1','CTCF-2','CTCF-3','H3K4me3-1','H3K4me3-2','H3K27ac-1','H3K27ac-2','Means-SNV','Means-CNV']\n",
    "feat_cols.extend(['HiC-{}'.format(i) for i in range(hic_mat.shape[1])])\n",
    "feat_df = pd.DataFrame(data=node_feat, columns=feat_cols)\n",
    "\n",
    "feat_df = pd.concat([GENE_LIST, feat_df], axis=1)\n",
    "feat_df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPI preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PPI matrix from data/CPDB/CPDB_matrix.csv ......\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0],\n",
       "       [0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0],\n",
       "       [0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0],\n",
       "       [0.0, 0.0, 0, 0.0, 0.7426669999999999, 0.0, 0.0, 0.0, 0, 0.0],\n",
       "       [0.0, 0.0, 0, 0.7426669999999999, 0.0, 0.0, 0.0, 0.0, 0, 0.0],\n",
       "       [0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0],\n",
       "       [0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0],\n",
       "       [0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0],\n",
       "       [0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0],\n",
       "       [0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0]], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_preprocess_cv import get_ppi_mat\n",
    "\n",
    "# PPI matrix named as \"{PPI_TYPE}_matrix.csv\" should be put into data/{PPI_TYPE} first.\n",
    "# For example, \"data/CPDB/CPDB_matrix.csv\"\n",
    "ppi_mat = get_ppi_mat(ppi_name='CPDB', from_list=False,) # this could take several minutes (2m 7s on our computer).\n",
    "ppi_mat[20:30, 20:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load gene labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 358.0. Negative samples: 1581.0. Unlabeled samples: 14226\n"
     ]
    }
   ],
   "source": [
    "from data_preprocess_cv import get_label\n",
    "\n",
    "node_lab, labeled_idx = get_label(data_dir=DATA_DIR, )\n",
    "labeled_lab = [node_lab[i][1] for i in labeled_idx]\n",
    "print(f\"Positive samples: {sum(node_lab)[1]}  Negative samples: {sum(node_lab)[0]}  Unlabeled samples: {len(node_lab) - len(labeled_idx)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build PyG Data instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges: 547530, Dimensionality of edge: 1,\n",
      "Nubmer of nodes: 16165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[16165, 15], edge_index=[2, 547530], edge_attr=[547530, 1], y=[16165, 2], pos=[16165], edge_dim=1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_preprocess_cv import build_pyg_data\n",
    "\n",
    "data = build_pyg_data(node_feat, node_lab, ppi_mat, pos) # this could take several minutes (1m 18s on our computer).\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do train-test split\n",
    "\n",
    "25% for test set, 75% for a 10-fold train-valid spilt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 Training set: 1308  Valid set: 146  Test set: 485\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "train_idx_list, valid_idx_list = [], []\n",
    "train_valid_idx, test_idx, train_valid_lab, test_lab = train_test_split(\n",
    "    labeled_idx, labeled_lab, test_size=0.25, stratify=labeled_lab, random_state=RANDOM_SEED)\n",
    "skf = StratifiedKFold(n_splits=CV_FOLDS, shuffle=True, random_state=RANDOM_SEED)\n",
    "for train_labeled_idx, valid_labeled_idx in skf.split(train_valid_idx, train_valid_lab):\n",
    "    valid_idx_list.append([train_valid_idx[i] for i in valid_labeled_idx])\n",
    "    train_idx_list.append([train_valid_idx[i] for i in train_labeled_idx])\n",
    "\n",
    "fold = 0\n",
    "print(f\"Fold {fold}  Training set: {len(train_idx_list[fold])}  Valid set: {len(valid_idx_list[fold])}  Test set: {len(test_idx)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create CancerDataset and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[16165, 15], edge_index=[2, 547530], edge_attr=[547530, 1], y=[16165, 2], pos=[16165], edge_dim=1, train_mask=[16165, 10], valid_mask=[16165, 10], test_mask=[16165], unlabeled_mask=[16165], num_classes=2)\n",
      "Finished! Saving dataset to data/Breast_Cancer_Matrix/MCF7_CPDB_dataset.pkl ......\n"
     ]
    }
   ],
   "source": [
    "from data_preprocess_cv import create_cv_dataset, CancerDataset, get_cell_line\n",
    "import pickle\n",
    "\n",
    "cv_dataset = create_cv_dataset(train_idx_list.copy(), valid_idx_list.copy(), test_idx.copy(), ppi_data=data)\n",
    "print(cv_dataset[0])\n",
    "dataset_dir = os.path.join(DATA_DIR, get_cell_line(DATA_DIR)[1:] + f'_{PPI}_dataset.pkl')\n",
    "print(f'Finished! Saving dataset to {dataset_dir} ......')\n",
    "with open(dataset_dir, 'wb') as f:\n",
    "    pickle.dump(cv_dataset, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and Train model <div id=\"load-data-and-train-model\"></div>\n",
    "A 10-fold training would cost m s on our computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from: data/Breast_Cancer_Matrix/MCF7_CPDB_dataset_final.pkl ......\n",
      "Doing below distrubs: \n",
      " {'add': [], 'remove': [], 'random': []}\n",
      "Data(x=[16165, 15], edge_index=[2, 547530], edge_attr=[547530, 1], y=[16165, 2], pos=[16165], edge_dim=1, train_mask=[16165, 10], valid_mask=[16165, 10], test_mask=[16165], unlabeled_mask=[16165], num_classes=2)\n",
      "Drop  0.5 of negative train samples\n",
      "Negatives: 534, Positives: 241\n",
      "Start Training\n",
      "Train AUPRC: 0.2019, AUROC: 0.2048, ACC: 0.5071\n",
      "Train AUPRC: 0.2208, AUROC: 0.3071, ACC: 0.6103\n",
      "Train AUPRC: 0.5394, AUROC: 0.7612, ACC: 0.6839\n",
      "Train AUPRC: 0.7523, AUROC: 0.9097, ACC: 0.8323\n",
      "Train AUPRC: 0.7626, AUROC: 0.9158, ACC: 0.8387\n",
      "Train AUPRC: 0.7821, AUROC: 0.9212, ACC: 0.8258\n",
      "Train AUPRC: 0.7728, AUROC: 0.9190, ACC: 0.8232\n",
      "Train AUPRC: 0.7746, AUROC: 0.9198, ACC: 0.8194\n",
      "Train AUPRC: 0.8098, AUROC: 0.9300, ACC: 0.8090\n",
      "Train AUPRC: 0.7947, AUROC: 0.9246, ACC: 0.8181\n",
      "Epoch: 9, Train loss: 0.5187, Acc: 0.8219, Auprc: 0.6597, TP: 26, F1: 0.6667, Auroc: 0.9315\n",
      "Train AUPRC: 0.7635, AUROC: 0.9173, ACC: 0.8503\n",
      "Train AUPRC: 0.8325, AUROC: 0.9354, ACC: 0.8155\n",
      "Train AUPRC: 0.8162, AUROC: 0.9290, ACC: 0.8335\n",
      "Train AUPRC: 0.7659, AUROC: 0.9181, ACC: 0.8748\n",
      "Train AUPRC: 0.8294, AUROC: 0.9360, ACC: 0.8219\n",
      "Train AUPRC: 0.8321, AUROC: 0.9369, ACC: 0.8219\n",
      "Train AUPRC: 0.7597, AUROC: 0.9168, ACC: 0.7768\n",
      "Train AUPRC: 0.7670, AUROC: 0.9178, ACC: 0.7290\n",
      "Train AUPRC: 0.8284, AUROC: 0.9343, ACC: 0.8619\n",
      "Train AUPRC: 0.8381, AUROC: 0.9389, ACC: 0.8219\n",
      "Epoch: 19, Train loss: 0.3619, Acc: 0.8288, Auprc: 0.6712, TP: 27, F1: 0.6835, Auroc: 0.9390\n",
      "Train AUPRC: 0.8386, AUROC: 0.9391, ACC: 0.8232\n",
      "Train AUPRC: 0.8344, AUROC: 0.9366, ACC: 0.8619\n",
      "Train AUPRC: 0.8244, AUROC: 0.9317, ACC: 0.8684\n",
      "Train AUPRC: 0.8315, AUROC: 0.9336, ACC: 0.8800\n",
      "Train AUPRC: 0.8445, AUROC: 0.9389, ACC: 0.8606\n",
      "Train AUPRC: 0.8450, AUROC: 0.9388, ACC: 0.8723\n",
      "Train AUPRC: 0.8394, AUROC: 0.9349, ACC: 0.8413\n",
      "Train AUPRC: 0.8456, AUROC: 0.9378, ACC: 0.8839\n",
      "Train AUPRC: 0.8520, AUROC: 0.9425, ACC: 0.8555\n",
      "Train AUPRC: 0.8525, AUROC: 0.9428, ACC: 0.8632\n",
      "Epoch: 29, Train loss: 0.3094, Acc: 0.8836, Auprc: 0.7424, TP: 24, F1: 0.7385, Auroc: 0.9427\n",
      "Train AUPRC: 0.8486, AUROC: 0.9385, ACC: 0.8658\n",
      "Train AUPRC: 0.8519, AUROC: 0.9407, ACC: 0.8916\n",
      "Train AUPRC: 0.8569, AUROC: 0.9447, ACC: 0.8568\n",
      "Train AUPRC: 0.8545, AUROC: 0.9447, ACC: 0.8026\n",
      "Train AUPRC: 0.8555, AUROC: 0.9448, ACC: 0.8013\n",
      "Train AUPRC: 0.8602, AUROC: 0.9453, ACC: 0.8297\n",
      "Train AUPRC: 0.8589, AUROC: 0.9415, ACC: 0.8800\n",
      "Train AUPRC: 0.8608, AUROC: 0.9418, ACC: 0.8813\n",
      "Train AUPRC: 0.8719, AUROC: 0.9456, ACC: 0.8697\n",
      "Train AUPRC: 0.8717, AUROC: 0.9448, ACC: 0.8929\n",
      "Epoch: 39, Train loss: 0.2826, Acc: 0.9110, Auprc: 0.7658, TP: 24, F1: 0.7869, Auroc: 0.9465\n",
      "Train AUPRC: 0.8731, AUROC: 0.9444, ACC: 0.8903\n",
      "Train AUPRC: 0.8777, AUROC: 0.9456, ACC: 0.8916\n",
      "Train AUPRC: 0.8810, AUROC: 0.9471, ACC: 0.8774\n",
      "Train AUPRC: 0.8832, AUROC: 0.9490, ACC: 0.8503\n",
      "Train AUPRC: 0.8856, AUROC: 0.9468, ACC: 0.8929\n",
      "Train AUPRC: 0.8896, AUROC: 0.9477, ACC: 0.8916\n",
      "Train AUPRC: 0.8947, AUROC: 0.9509, ACC: 0.8477\n",
      "Train AUPRC: 0.8970, AUROC: 0.9499, ACC: 0.8916\n",
      "Train AUPRC: 0.8964, AUROC: 0.9496, ACC: 0.8813\n",
      "Train AUPRC: 0.9070, AUROC: 0.9532, ACC: 0.8748\n",
      "Epoch: 49, Train loss: 0.2659, Acc: 0.8904, Auprc: 0.8258, TP: 24, F1: 0.7500, Auroc: 0.9558\n",
      "Train AUPRC: 0.9031, AUROC: 0.9520, ACC: 0.8826\n",
      "Train AUPRC: 0.9083, AUROC: 0.9533, ACC: 0.8903\n",
      "Train AUPRC: 0.9009, AUROC: 0.9528, ACC: 0.8219\n",
      "Train AUPRC: 0.9037, AUROC: 0.9537, ACC: 0.8477\n",
      "Train AUPRC: 0.9095, AUROC: 0.9540, ACC: 0.8890\n",
      "Train AUPRC: 0.9090, AUROC: 0.9538, ACC: 0.8787\n",
      "Train AUPRC: 0.9037, AUROC: 0.9541, ACC: 0.8632\n",
      "Train AUPRC: 0.9019, AUROC: 0.9539, ACC: 0.8271\n",
      "Train AUPRC: 0.9077, AUROC: 0.9545, ACC: 0.8542\n",
      "Train AUPRC: 0.9108, AUROC: 0.9546, ACC: 0.8903\n",
      "Epoch: 59, Train loss: 0.2634, Acc: 0.8904, Auprc: 0.8573, TP: 19, F1: 0.7037, Auroc: 0.9608\n",
      "Train AUPRC: 0.9124, AUROC: 0.9553, ACC: 0.8968\n",
      "Train AUPRC: 0.9109, AUROC: 0.9553, ACC: 0.8516\n",
      "Train AUPRC: 0.9115, AUROC: 0.9554, ACC: 0.8929\n",
      "Train AUPRC: 0.9059, AUROC: 0.9535, ACC: 0.8658\n",
      "Train AUPRC: 0.9104, AUROC: 0.9551, ACC: 0.9006\n",
      "Train AUPRC: 0.9126, AUROC: 0.9562, ACC: 0.8684\n",
      "Train AUPRC: 0.9117, AUROC: 0.9561, ACC: 0.8684\n",
      "Train AUPRC: 0.9130, AUROC: 0.9562, ACC: 0.9019\n",
      "Train AUPRC: 0.9139, AUROC: 0.9564, ACC: 0.8890\n",
      "Train AUPRC: 0.9168, AUROC: 0.9571, ACC: 0.8994\n",
      "Epoch: 69, Train loss: 0.2661, Acc: 0.8904, Auprc: 0.8591, TP: 19, F1: 0.7037, Auroc: 0.9599\n",
      "Train AUPRC: 0.9212, AUROC: 0.9578, ACC: 0.9006\n",
      "Train AUPRC: 0.9239, AUROC: 0.9585, ACC: 0.8916\n",
      "Train AUPRC: 0.9255, AUROC: 0.9589, ACC: 0.8916\n",
      "Train AUPRC: 0.9179, AUROC: 0.9565, ACC: 0.8606\n",
      "Train AUPRC: 0.9111, AUROC: 0.9536, ACC: 0.8206\n",
      "Train AUPRC: 0.9267, AUROC: 0.9590, ACC: 0.8632\n",
      "Train AUPRC: 0.9208, AUROC: 0.9574, ACC: 0.8142\n",
      "Train AUPRC: 0.9177, AUROC: 0.9563, ACC: 0.8439\n",
      "Train AUPRC: 0.9179, AUROC: 0.9565, ACC: 0.8787\n",
      "Train AUPRC: 0.9210, AUROC: 0.9574, ACC: 0.8839\n",
      "Epoch: 79, Train loss: 0.2766, Acc: 0.8904, Auprc: 0.8542, TP: 24, F1: 0.7500, Auroc: 0.9617\n",
      "Train AUPRC: 0.9230, AUROC: 0.9579, ACC: 0.8916\n",
      "Train AUPRC: 0.9245, AUROC: 0.9582, ACC: 0.8994\n",
      "Train AUPRC: 0.9243, AUROC: 0.9580, ACC: 0.8929\n",
      "Train AUPRC: 0.9253, AUROC: 0.9585, ACC: 0.8942\n",
      "Train AUPRC: 0.9256, AUROC: 0.9588, ACC: 0.8761\n",
      "Train AUPRC: 0.9247, AUROC: 0.9583, ACC: 0.8955\n",
      "Train AUPRC: 0.9197, AUROC: 0.9562, ACC: 0.8813\n",
      "Train AUPRC: 0.9267, AUROC: 0.9594, ACC: 0.8994\n",
      "Train AUPRC: 0.9270, AUROC: 0.9600, ACC: 0.8735\n",
      "Train AUPRC: 0.9271, AUROC: 0.9603, ACC: 0.8697\n",
      "Epoch: 89, Train loss: 0.2716, Acc: 0.8836, Auprc: 0.8656, TP: 26, F1: 0.7536, Auroc: 0.9639\n",
      "Train AUPRC: 0.9280, AUROC: 0.9607, ACC: 0.8955\n",
      "Train AUPRC: 0.9284, AUROC: 0.9610, ACC: 0.8968\n",
      "Train AUPRC: 0.9262, AUROC: 0.9601, ACC: 0.8684\n",
      "Train AUPRC: 0.9265, AUROC: 0.9605, ACC: 0.8813\n",
      "Train AUPRC: 0.9283, AUROC: 0.9613, ACC: 0.9071\n",
      "Train AUPRC: 0.9290, AUROC: 0.9617, ACC: 0.9019\n",
      "Train AUPRC: 0.9281, AUROC: 0.9615, ACC: 0.8981\n",
      "Train AUPRC: 0.9274, AUROC: 0.9615, ACC: 0.8813\n",
      "Train AUPRC: 0.9289, AUROC: 0.9623, ACC: 0.9032\n",
      "Train AUPRC: 0.9296, AUROC: 0.9626, ACC: 0.8942\n",
      "Epoch: 99, Train loss: 0.2238, Acc: 0.8836, Auprc: 0.8586, TP: 17, F1: 0.6667, Auroc: 0.9580\n",
      "Train AUPRC: 0.9305, AUROC: 0.9628, ACC: 0.9058\n",
      "Train AUPRC: 0.9305, AUROC: 0.9626, ACC: 0.9045\n",
      "Train AUPRC: 0.9305, AUROC: 0.9627, ACC: 0.9019\n",
      "Train AUPRC: 0.9305, AUROC: 0.9627, ACC: 0.8942\n",
      "Train AUPRC: 0.9317, AUROC: 0.9634, ACC: 0.9071\n",
      "Train AUPRC: 0.9322, AUROC: 0.9637, ACC: 0.9084\n",
      "Train AUPRC: 0.9319, AUROC: 0.9633, ACC: 0.8877\n",
      "Train AUPRC: 0.9332, AUROC: 0.9642, ACC: 0.8994\n",
      "Train AUPRC: 0.9351, AUROC: 0.9650, ACC: 0.9135\n",
      "Train AUPRC: 0.9364, AUROC: 0.9654, ACC: 0.9110\n",
      "Epoch: 109, Train loss: 0.2144, Acc: 0.9110, Auprc: 0.8664, TP: 22, F1: 0.7719, Auroc: 0.9614\n",
      "Train AUPRC: 0.9371, AUROC: 0.9656, ACC: 0.9084\n",
      "Train AUPRC: 0.9380, AUROC: 0.9659, ACC: 0.9161\n",
      "Train AUPRC: 0.9383, AUROC: 0.9662, ACC: 0.9161\n",
      "Train AUPRC: 0.9382, AUROC: 0.9661, ACC: 0.9148\n",
      "Train AUPRC: 0.9331, AUROC: 0.9640, ACC: 0.8839\n",
      "Train AUPRC: 0.9379, AUROC: 0.9659, ACC: 0.9058\n",
      "Train AUPRC: 0.9385, AUROC: 0.9657, ACC: 0.8839\n",
      "Train AUPRC: 0.9398, AUROC: 0.9664, ACC: 0.9032\n",
      "Train AUPRC: 0.9396, AUROC: 0.9664, ACC: 0.9123\n",
      "Train AUPRC: 0.9402, AUROC: 0.9665, ACC: 0.9123\n",
      "Epoch: 119, Train loss: 0.2788, Acc: 0.9110, Auprc: 0.8713, TP: 24, F1: 0.7869, Auroc: 0.9630\n",
      "Train AUPRC: 0.9394, AUROC: 0.9657, ACC: 0.8774\n",
      "Train AUPRC: 0.9403, AUROC: 0.9666, ACC: 0.9174\n",
      "Train AUPRC: 0.9292, AUROC: 0.9618, ACC: 0.8503\n",
      "Train AUPRC: 0.9374, AUROC: 0.9662, ACC: 0.9148\n",
      "Train AUPRC: 0.9367, AUROC: 0.9655, ACC: 0.8710\n",
      "Train AUPRC: 0.9365, AUROC: 0.9655, ACC: 0.8748\n",
      "Train AUPRC: 0.9373, AUROC: 0.9660, ACC: 0.8942\n",
      "Train AUPRC: 0.9374, AUROC: 0.9657, ACC: 0.9135\n",
      "Train AUPRC: 0.9374, AUROC: 0.9653, ACC: 0.9123\n",
      "Train AUPRC: 0.9381, AUROC: 0.9653, ACC: 0.9161\n",
      "Epoch: 129, Train loss: 0.1910, Acc: 0.9178, Auprc: 0.8652, TP: 24, F1: 0.8000, Auroc: 0.9623\n",
      "Train AUPRC: 0.9391, AUROC: 0.9656, ACC: 0.9123\n",
      "Train AUPRC: 0.9399, AUROC: 0.9659, ACC: 0.9071\n",
      "Train AUPRC: 0.9403, AUROC: 0.9663, ACC: 0.9187\n",
      "Train AUPRC: 0.9373, AUROC: 0.9648, ACC: 0.9084\n",
      "Train AUPRC: 0.9398, AUROC: 0.9662, ACC: 0.9148\n",
      "Train AUPRC: 0.9417, AUROC: 0.9672, ACC: 0.9019\n",
      "Train AUPRC: 0.9421, AUROC: 0.9674, ACC: 0.9019\n",
      "Train AUPRC: 0.9421, AUROC: 0.9674, ACC: 0.9213\n",
      "Train AUPRC: 0.9416, AUROC: 0.9672, ACC: 0.9148\n",
      "Train AUPRC: 0.9431, AUROC: 0.9682, ACC: 0.9097\n",
      "Epoch: 139, Train loss: 0.2634, Acc: 0.9110, Auprc: 0.8722, TP: 24, F1: 0.7869, Auroc: 0.9655\n",
      "Train AUPRC: 0.9429, AUROC: 0.9680, ACC: 0.9058\n",
      "Train AUPRC: 0.9425, AUROC: 0.9679, ACC: 0.9032\n",
      "Train AUPRC: 0.9433, AUROC: 0.9683, ACC: 0.9148\n",
      "Train AUPRC: 0.9440, AUROC: 0.9686, ACC: 0.9239\n",
      "Train AUPRC: 0.9411, AUROC: 0.9670, ACC: 0.9058\n",
      "Train AUPRC: 0.9446, AUROC: 0.9690, ACC: 0.9252\n",
      "Train AUPRC: 0.9453, AUROC: 0.9692, ACC: 0.9071\n",
      "Train AUPRC: 0.9456, AUROC: 0.9691, ACC: 0.8968\n",
      "Train AUPRC: 0.9463, AUROC: 0.9695, ACC: 0.9058\n",
      "Train AUPRC: 0.9461, AUROC: 0.9697, ACC: 0.9226\n",
      "Epoch: 149, Train loss: 0.3033, Acc: 0.9247, Auprc: 0.8611, TP: 23, F1: 0.8070, Auroc: 0.9620\n",
      "Train AUPRC: 0.9469, AUROC: 0.9699, ACC: 0.9239\n",
      "Train AUPRC: 0.9473, AUROC: 0.9697, ACC: 0.9161\n",
      "Train AUPRC: 0.9476, AUROC: 0.9699, ACC: 0.9226\n",
      "Train AUPRC: 0.9468, AUROC: 0.9697, ACC: 0.9135\n",
      "Train AUPRC: 0.9475, AUROC: 0.9700, ACC: 0.9226\n",
      "Train AUPRC: 0.9473, AUROC: 0.9699, ACC: 0.9226\n",
      "Train AUPRC: 0.9466, AUROC: 0.9692, ACC: 0.9071\n",
      "Train AUPRC: 0.9472, AUROC: 0.9696, ACC: 0.9213\n",
      "Train AUPRC: 0.9479, AUROC: 0.9702, ACC: 0.9239\n",
      "Train AUPRC: 0.9486, AUROC: 0.9704, ACC: 0.9174\n",
      "Epoch: 159, Train loss: 0.4300, Acc: 0.9041, Auprc: 0.8740, TP: 24, F1: 0.7742, Auroc: 0.9655\n",
      "Train AUPRC: 0.9480, AUROC: 0.9697, ACC: 0.8865\n",
      "Train AUPRC: 0.9498, AUROC: 0.9712, ACC: 0.9148\n",
      "Train AUPRC: 0.9472, AUROC: 0.9700, ACC: 0.9123\n",
      "Train AUPRC: 0.9456, AUROC: 0.9692, ACC: 0.9045\n",
      "Train AUPRC: 0.9511, AUROC: 0.9718, ACC: 0.9252\n",
      "Train AUPRC: 0.9501, AUROC: 0.9712, ACC: 0.9187\n",
      "Train AUPRC: 0.9501, AUROC: 0.9711, ACC: 0.9135\n",
      "Train AUPRC: 0.9511, AUROC: 0.9719, ACC: 0.9226\n",
      "Train AUPRC: 0.9520, AUROC: 0.9725, ACC: 0.9239\n",
      "Train AUPRC: 0.9499, AUROC: 0.9713, ACC: 0.9161\n",
      "Epoch: 169, Train loss: 0.2065, Acc: 0.9247, Auprc: 0.8639, TP: 22, F1: 0.8000, Auroc: 0.9558\n",
      "Train AUPRC: 0.9504, AUROC: 0.9715, ACC: 0.9239\n",
      "Train AUPRC: 0.9497, AUROC: 0.9710, ACC: 0.9161\n",
      "Train AUPRC: 0.9502, AUROC: 0.9712, ACC: 0.9277\n",
      "Train AUPRC: 0.9501, AUROC: 0.9710, ACC: 0.9239\n",
      "Train AUPRC: 0.9490, AUROC: 0.9706, ACC: 0.9161\n",
      "Train AUPRC: 0.9486, AUROC: 0.9704, ACC: 0.9110\n",
      "Train AUPRC: 0.9500, AUROC: 0.9713, ACC: 0.9226\n",
      "Train AUPRC: 0.9433, AUROC: 0.9679, ACC: 0.9032\n",
      "Train AUPRC: 0.9494, AUROC: 0.9711, ACC: 0.9252\n",
      "Train AUPRC: 0.9453, AUROC: 0.9687, ACC: 0.8903\n",
      "Epoch: 179, Train loss: 0.2599, Acc: 0.8836, Auprc: 0.8817, TP: 24, F1: 0.7385, Auroc: 0.9689\n",
      "Train AUPRC: 0.9446, AUROC: 0.9683, ACC: 0.8890\n",
      "Train AUPRC: 0.9470, AUROC: 0.9699, ACC: 0.9161\n",
      "Train AUPRC: 0.9480, AUROC: 0.9706, ACC: 0.9252\n",
      "Train AUPRC: 0.9483, AUROC: 0.9704, ACC: 0.9239\n",
      "Train AUPRC: 0.9469, AUROC: 0.9695, ACC: 0.8968\n",
      "Train AUPRC: 0.9472, AUROC: 0.9695, ACC: 0.8903\n",
      "Train AUPRC: 0.9491, AUROC: 0.9705, ACC: 0.9097\n",
      "Train AUPRC: 0.9510, AUROC: 0.9715, ACC: 0.9277\n",
      "Train AUPRC: 0.9508, AUROC: 0.9713, ACC: 0.9174\n",
      "Train AUPRC: 0.9499, AUROC: 0.9710, ACC: 0.9097\n",
      "Epoch: 189, Train loss: 0.2641, Acc: 0.9315, Auprc: 0.8741, TP: 21, F1: 0.8077, Auroc: 0.9639\n",
      "Train AUPRC: 0.9526, AUROC: 0.9722, ACC: 0.9174\n",
      "Train AUPRC: 0.9529, AUROC: 0.9722, ACC: 0.9252\n",
      "Train AUPRC: 0.9532, AUROC: 0.9724, ACC: 0.9265\n",
      "Train AUPRC: 0.9543, AUROC: 0.9730, ACC: 0.9329\n",
      "Train AUPRC: 0.9545, AUROC: 0.9731, ACC: 0.9265\n",
      "Train AUPRC: 0.9534, AUROC: 0.9730, ACC: 0.9148\n",
      "Train AUPRC: 0.9533, AUROC: 0.9733, ACC: 0.9316\n",
      "Train AUPRC: 0.9519, AUROC: 0.9725, ACC: 0.9213\n",
      "Train AUPRC: 0.9525, AUROC: 0.9730, ACC: 0.9290\n",
      "Train AUPRC: 0.9531, AUROC: 0.9735, ACC: 0.9303\n",
      "Epoch: 199, Train loss: 0.2052, Acc: 0.9178, Auprc: 0.8939, TP: 24, F1: 0.8000, Auroc: 0.9686\n",
      "Train AUPRC: 0.9534, AUROC: 0.9735, ACC: 0.9290\n",
      "Train AUPRC: 0.9538, AUROC: 0.9733, ACC: 0.9316\n",
      "Train AUPRC: 0.9538, AUROC: 0.9734, ACC: 0.9265\n",
      "Train AUPRC: 0.9540, AUROC: 0.9734, ACC: 0.9252\n",
      "Train AUPRC: 0.9541, AUROC: 0.9734, ACC: 0.9265\n",
      "Train AUPRC: 0.9540, AUROC: 0.9734, ACC: 0.9290\n",
      "Train AUPRC: 0.9535, AUROC: 0.9730, ACC: 0.9200\n",
      "Train AUPRC: 0.9550, AUROC: 0.9738, ACC: 0.9265\n",
      "Train AUPRC: 0.9555, AUROC: 0.9740, ACC: 0.9303\n",
      "Train AUPRC: 0.9552, AUROC: 0.9737, ACC: 0.9277\n",
      "Epoch: 209, Train loss: 0.2122, Acc: 0.9110, Auprc: 0.8893, TP: 24, F1: 0.7869, Auroc: 0.9655\n",
      "Train AUPRC: 0.9531, AUROC: 0.9721, ACC: 0.8890\n",
      "Train AUPRC: 0.9490, AUROC: 0.9694, ACC: 0.8490\n",
      "Train AUPRC: 0.9510, AUROC: 0.9711, ACC: 0.8929\n",
      "Train AUPRC: 0.9527, AUROC: 0.9728, ACC: 0.9213\n",
      "Train AUPRC: 0.9517, AUROC: 0.9724, ACC: 0.9148\n",
      "Train AUPRC: 0.9532, AUROC: 0.9728, ACC: 0.9265\n",
      "Train AUPRC: 0.9504, AUROC: 0.9708, ACC: 0.8877\n",
      "Train AUPRC: 0.9499, AUROC: 0.9699, ACC: 0.8761\n",
      "Train AUPRC: 0.9517, AUROC: 0.9712, ACC: 0.8994\n",
      "Train AUPRC: 0.9549, AUROC: 0.9732, ACC: 0.9303\n",
      "Epoch: 219, Train loss: 0.2517, Acc: 0.9315, Auprc: 0.8947, TP: 24, F1: 0.8276, Auroc: 0.9704\n",
      "Train AUPRC: 0.9554, AUROC: 0.9735, ACC: 0.9200\n",
      "Train AUPRC: 0.9557, AUROC: 0.9736, ACC: 0.9239\n",
      "Train AUPRC: 0.9555, AUROC: 0.9734, ACC: 0.9303\n",
      "Train AUPRC: 0.9550, AUROC: 0.9732, ACC: 0.9290\n",
      "Train AUPRC: 0.9545, AUROC: 0.9729, ACC: 0.9200\n",
      "Train AUPRC: 0.9546, AUROC: 0.9730, ACC: 0.9316\n",
      "Train AUPRC: 0.9553, AUROC: 0.9735, ACC: 0.9303\n",
      "Train AUPRC: 0.9556, AUROC: 0.9737, ACC: 0.9329\n",
      "Train AUPRC: 0.9560, AUROC: 0.9739, ACC: 0.9252\n",
      "Train AUPRC: 0.9553, AUROC: 0.9736, ACC: 0.9187\n",
      "Epoch: 229, Train loss: 0.1768, Acc: 0.9315, Auprc: 0.8817, TP: 22, F1: 0.8148, Auroc: 0.9651\n",
      "Train AUPRC: 0.9563, AUROC: 0.9741, ACC: 0.9252\n",
      "Train AUPRC: 0.9563, AUROC: 0.9740, ACC: 0.9342\n",
      "Train AUPRC: 0.9560, AUROC: 0.9738, ACC: 0.9290\n",
      "Train AUPRC: 0.9562, AUROC: 0.9739, ACC: 0.9290\n",
      "Train AUPRC: 0.9573, AUROC: 0.9746, ACC: 0.9329\n",
      "Train AUPRC: 0.9576, AUROC: 0.9749, ACC: 0.9239\n",
      "Train AUPRC: 0.9567, AUROC: 0.9745, ACC: 0.9187\n",
      "Train AUPRC: 0.9575, AUROC: 0.9748, ACC: 0.9303\n",
      "Train AUPRC: 0.9571, AUROC: 0.9744, ACC: 0.9277\n",
      "Train AUPRC: 0.9575, AUROC: 0.9749, ACC: 0.9303\n",
      "Epoch: 239, Train loss: 0.1765, Acc: 0.9315, Auprc: 0.8977, TP: 24, F1: 0.8276, Auroc: 0.9701\n",
      "Train AUPRC: 0.9576, AUROC: 0.9751, ACC: 0.9303\n",
      "Train AUPRC: 0.9566, AUROC: 0.9746, ACC: 0.9200\n",
      "Train AUPRC: 0.9574, AUROC: 0.9748, ACC: 0.9316\n",
      "Train AUPRC: 0.9552, AUROC: 0.9733, ACC: 0.9161\n",
      "Train AUPRC: 0.9549, AUROC: 0.9730, ACC: 0.9058\n",
      "Train AUPRC: 0.9574, AUROC: 0.9746, ACC: 0.9329\n",
      "Train AUPRC: 0.9560, AUROC: 0.9741, ACC: 0.9187\n",
      "Train AUPRC: 0.9564, AUROC: 0.9744, ACC: 0.9187\n",
      "Train AUPRC: 0.9578, AUROC: 0.9748, ACC: 0.9329\n",
      "Train AUPRC: 0.9581, AUROC: 0.9746, ACC: 0.9316\n",
      "Epoch: 249, Train loss: 0.2631, Acc: 0.9110, Auprc: 0.8910, TP: 24, F1: 0.7869, Auroc: 0.9661\n",
      "Train AUPRC: 0.9582, AUROC: 0.9747, ACC: 0.9329\n",
      "Train AUPRC: 0.9584, AUROC: 0.9749, ACC: 0.9316\n",
      "Train AUPRC: 0.9580, AUROC: 0.9747, ACC: 0.9329\n",
      "Train AUPRC: 0.9577, AUROC: 0.9744, ACC: 0.9342\n",
      "Train AUPRC: 0.9576, AUROC: 0.9742, ACC: 0.9329\n",
      "Train AUPRC: 0.9579, AUROC: 0.9744, ACC: 0.9277\n",
      "Train AUPRC: 0.9579, AUROC: 0.9745, ACC: 0.9303\n",
      "Train AUPRC: 0.9579, AUROC: 0.9744, ACC: 0.9252\n",
      "Train AUPRC: 0.9579, AUROC: 0.9745, ACC: 0.9252\n",
      "Train AUPRC: 0.9580, AUROC: 0.9746, ACC: 0.9329\n",
      "Epoch: 259, Train loss: 0.1924, Acc: 0.9247, Auprc: 0.9028, TP: 24, F1: 0.8136, Auroc: 0.9711\n",
      "Train AUPRC: 0.9583, AUROC: 0.9747, ACC: 0.9226\n",
      "Train AUPRC: 0.9583, AUROC: 0.9748, ACC: 0.9329\n",
      "Train AUPRC: 0.9583, AUROC: 0.9750, ACC: 0.9355\n",
      "Train AUPRC: 0.9582, AUROC: 0.9749, ACC: 0.9329\n",
      "Train AUPRC: 0.9579, AUROC: 0.9746, ACC: 0.9226\n",
      "Train AUPRC: 0.9579, AUROC: 0.9745, ACC: 0.9265\n",
      "Train AUPRC: 0.9586, AUROC: 0.9752, ACC: 0.9368\n",
      "Train AUPRC: 0.9584, AUROC: 0.9751, ACC: 0.9303\n",
      "Train AUPRC: 0.9587, AUROC: 0.9753, ACC: 0.9342\n",
      "Train AUPRC: 0.9590, AUROC: 0.9752, ACC: 0.9252\n",
      "Epoch: 269, Train loss: 0.2204, Acc: 0.9110, Auprc: 0.8963, TP: 24, F1: 0.7869, Auroc: 0.9689\n",
      "Train AUPRC: 0.9596, AUROC: 0.9757, ACC: 0.9368\n",
      "Train AUPRC: 0.9589, AUROC: 0.9754, ACC: 0.9290\n",
      "Train AUPRC: 0.9626, AUROC: 0.9769, ACC: 0.9329\n",
      "Train AUPRC: 0.9618, AUROC: 0.9759, ACC: 0.8877\n",
      "Train AUPRC: 0.9608, AUROC: 0.9755, ACC: 0.8916\n",
      "Train AUPRC: 0.9622, AUROC: 0.9765, ACC: 0.9342\n",
      "Train AUPRC: 0.9620, AUROC: 0.9765, ACC: 0.9355\n",
      "Train AUPRC: 0.9610, AUROC: 0.9760, ACC: 0.9316\n",
      "Train AUPRC: 0.9590, AUROC: 0.9747, ACC: 0.9329\n",
      "Train AUPRC: 0.9590, AUROC: 0.9747, ACC: 0.9316\n",
      "Epoch: 279, Train loss: 0.3313, Acc: 0.9110, Auprc: 0.9032, TP: 24, F1: 0.7869, Auroc: 0.9739\n",
      "Train AUPRC: 0.9588, AUROC: 0.9745, ACC: 0.9290\n",
      "Train AUPRC: 0.9596, AUROC: 0.9749, ACC: 0.9342\n",
      "Train AUPRC: 0.9616, AUROC: 0.9762, ACC: 0.9329\n",
      "Train AUPRC: 0.9627, AUROC: 0.9770, ACC: 0.9265\n",
      "Train AUPRC: 0.9624, AUROC: 0.9768, ACC: 0.9355\n",
      "Train AUPRC: 0.9613, AUROC: 0.9761, ACC: 0.9303\n",
      "Train AUPRC: 0.9604, AUROC: 0.9756, ACC: 0.9329\n",
      "Train AUPRC: 0.9596, AUROC: 0.9751, ACC: 0.9290\n",
      "Train AUPRC: 0.9603, AUROC: 0.9756, ACC: 0.9329\n",
      "Train AUPRC: 0.9608, AUROC: 0.9760, ACC: 0.9316\n",
      "Epoch: 289, Train loss: 0.1834, Acc: 0.9178, Auprc: 0.9000, TP: 24, F1: 0.8000, Auroc: 0.9711\n",
      "Train AUPRC: 0.9614, AUROC: 0.9765, ACC: 0.9316\n",
      "Train AUPRC: 0.9615, AUROC: 0.9766, ACC: 0.9316\n",
      "Train AUPRC: 0.9618, AUROC: 0.9769, ACC: 0.9329\n",
      "Train AUPRC: 0.9621, AUROC: 0.9769, ACC: 0.9368\n",
      "Train AUPRC: 0.9625, AUROC: 0.9770, ACC: 0.9342\n",
      "Train AUPRC: 0.9634, AUROC: 0.9777, ACC: 0.9394\n",
      "Train AUPRC: 0.9637, AUROC: 0.9778, ACC: 0.9445\n",
      "Train AUPRC: 0.9638, AUROC: 0.9778, ACC: 0.9458\n",
      "Train AUPRC: 0.9633, AUROC: 0.9775, ACC: 0.9394\n",
      "Train AUPRC: 0.9632, AUROC: 0.9775, ACC: 0.9394\n",
      "Epoch: 299, Train loss: 0.2471, Acc: 0.9247, Auprc: 0.9014, TP: 24, F1: 0.8136, Auroc: 0.9698\n",
      "Train AUPRC: 0.9632, AUROC: 0.9777, ACC: 0.9432\n",
      "Train AUPRC: 0.9628, AUROC: 0.9775, ACC: 0.9432\n",
      "Train AUPRC: 0.9629, AUROC: 0.9775, ACC: 0.9432\n",
      "Train AUPRC: 0.9629, AUROC: 0.9775, ACC: 0.9419\n",
      "Train AUPRC: 0.9628, AUROC: 0.9774, ACC: 0.9355\n",
      "Train AUPRC: 0.9615, AUROC: 0.9765, ACC: 0.9213\n",
      "Train AUPRC: 0.9602, AUROC: 0.9756, ACC: 0.9058\n",
      "Train AUPRC: 0.9609, AUROC: 0.9760, ACC: 0.9148\n",
      "Train AUPRC: 0.9611, AUROC: 0.9762, ACC: 0.9161\n",
      "Train AUPRC: 0.9636, AUROC: 0.9777, ACC: 0.9445\n",
      "Epoch: 309, Train loss: 0.1681, Acc: 0.9110, Auprc: 0.8991, TP: 22, F1: 0.7719, Auroc: 0.9673\n",
      "Train AUPRC: 0.9640, AUROC: 0.9780, ACC: 0.9368\n",
      "Train AUPRC: 0.9639, AUROC: 0.9780, ACC: 0.9368\n",
      "Train AUPRC: 0.9636, AUROC: 0.9778, ACC: 0.9406\n",
      "Train AUPRC: 0.9625, AUROC: 0.9771, ACC: 0.9329\n",
      "Train AUPRC: 0.9633, AUROC: 0.9776, ACC: 0.9381\n",
      "Train AUPRC: 0.9640, AUROC: 0.9779, ACC: 0.9394\n",
      "Train AUPRC: 0.9640, AUROC: 0.9778, ACC: 0.9394\n",
      "Train AUPRC: 0.9640, AUROC: 0.9780, ACC: 0.9406\n",
      "Train AUPRC: 0.9631, AUROC: 0.9773, ACC: 0.9342\n",
      "Train AUPRC: 0.9616, AUROC: 0.9765, ACC: 0.9290\n",
      "Epoch: 319, Train loss: 0.1826, Acc: 0.9041, Auprc: 0.8899, TP: 24, F1: 0.7742, Auroc: 0.9698\n",
      "Train AUPRC: 0.9616, AUROC: 0.9765, ACC: 0.9277\n",
      "Train AUPRC: 0.9625, AUROC: 0.9771, ACC: 0.9329\n",
      "Train AUPRC: 0.9632, AUROC: 0.9775, ACC: 0.9381\n",
      "Train AUPRC: 0.9638, AUROC: 0.9779, ACC: 0.9394\n",
      "Train AUPRC: 0.9636, AUROC: 0.9778, ACC: 0.9368\n",
      "Train AUPRC: 0.9635, AUROC: 0.9779, ACC: 0.9355\n",
      "Train AUPRC: 0.9638, AUROC: 0.9780, ACC: 0.9419\n",
      "Train AUPRC: 0.9633, AUROC: 0.9778, ACC: 0.9406\n",
      "Train AUPRC: 0.9628, AUROC: 0.9774, ACC: 0.9394\n",
      "Train AUPRC: 0.9629, AUROC: 0.9775, ACC: 0.9406\n",
      "Epoch: 329, Train loss: 0.1959, Acc: 0.9041, Auprc: 0.8886, TP: 23, F1: 0.7667, Auroc: 0.9689\n",
      "Train AUPRC: 0.9634, AUROC: 0.9777, ACC: 0.9406\n",
      "Train AUPRC: 0.9638, AUROC: 0.9780, ACC: 0.9406\n",
      "Train AUPRC: 0.9646, AUROC: 0.9784, ACC: 0.9432\n",
      "Train AUPRC: 0.9650, AUROC: 0.9786, ACC: 0.9394\n",
      "Train AUPRC: 0.9646, AUROC: 0.9784, ACC: 0.9432\n",
      "Train AUPRC: 0.9645, AUROC: 0.9783, ACC: 0.9432\n",
      "Train AUPRC: 0.9640, AUROC: 0.9780, ACC: 0.9394\n",
      "Train AUPRC: 0.9635, AUROC: 0.9777, ACC: 0.9316\n",
      "Train AUPRC: 0.9635, AUROC: 0.9776, ACC: 0.9316\n",
      "Train AUPRC: 0.9635, AUROC: 0.9776, ACC: 0.9329\n",
      "Epoch: 339, Train loss: 0.2281, Acc: 0.9178, Auprc: 0.9064, TP: 24, F1: 0.8000, Auroc: 0.9723\n",
      "Train AUPRC: 0.9632, AUROC: 0.9774, ACC: 0.9316\n",
      "Train AUPRC: 0.9624, AUROC: 0.9768, ACC: 0.9239\n",
      "Train AUPRC: 0.9621, AUROC: 0.9766, ACC: 0.9213\n",
      "Train AUPRC: 0.9633, AUROC: 0.9773, ACC: 0.9277\n",
      "Train AUPRC: 0.9646, AUROC: 0.9781, ACC: 0.9406\n",
      "Early Stopping\n",
      "Loading model from outs/MCF7_CPDB/0_0.9102_0.9760_24.pkl ......\n",
      "Drop  0.5 of negative train samples\n",
      "Negatives: 534, Positives: 241\n",
      "Start Training\n",
      "Train AUPRC: 0.4325, AUROC: 0.6324, ACC: 0.3110\n",
      "Train AUPRC: 0.6211, AUROC: 0.7904, ACC: 0.3110\n",
      "Train AUPRC: 0.7663, AUROC: 0.9064, ACC: 0.3110\n",
      "Train AUPRC: 0.8179, AUROC: 0.9206, ACC: 0.3110\n",
      "Train AUPRC: 0.8181, AUROC: 0.9238, ACC: 0.3110\n",
      "Train AUPRC: 0.8064, AUROC: 0.9249, ACC: 0.3110\n",
      "Train AUPRC: 0.7805, AUROC: 0.9236, ACC: 0.6245\n",
      "Train AUPRC: 0.7092, AUROC: 0.9065, ACC: 0.8090\n",
      "Train AUPRC: 0.6760, AUROC: 0.8869, ACC: 0.8142\n",
      "Train AUPRC: 0.6653, AUROC: 0.8818, ACC: 0.8194\n",
      "Epoch: 9, Train loss: 0.6375, Acc: 0.8082, Auprc: 0.4922, TP: 25, F1: 0.6410, Auroc: 0.8618\n",
      "Train AUPRC: 0.7005, AUROC: 0.8962, ACC: 0.8194\n",
      "Train AUPRC: 0.7605, AUROC: 0.9196, ACC: 0.8103\n",
      "Train AUPRC: 0.7634, AUROC: 0.9196, ACC: 0.8116\n",
      "Train AUPRC: 0.6994, AUROC: 0.8947, ACC: 0.8426\n",
      "Train AUPRC: 0.7557, AUROC: 0.9142, ACC: 0.8232\n",
      "Train AUPRC: 0.8059, AUROC: 0.9294, ACC: 0.8155\n",
      "Train AUPRC: 0.7820, AUROC: 0.9233, ACC: 0.8271\n",
      "Train AUPRC: 0.8192, AUROC: 0.9337, ACC: 0.8245\n",
      "Train AUPRC: 0.8293, AUROC: 0.9354, ACC: 0.8232\n",
      "Train AUPRC: 0.8608, AUROC: 0.9427, ACC: 0.8142\n",
      "Epoch: 19, Train loss: 0.3444, Acc: 0.7671, Auprc: 0.7449, TP: 25, F1: 0.5952, Auroc: 0.9284\n",
      "Train AUPRC: 0.8448, AUROC: 0.9401, ACC: 0.8168\n",
      "Train AUPRC: 0.8121, AUROC: 0.9342, ACC: 0.8800\n",
      "Train AUPRC: 0.8441, AUROC: 0.9407, ACC: 0.8465\n",
      "Train AUPRC: 0.8555, AUROC: 0.9434, ACC: 0.8619\n",
      "Train AUPRC: 0.8285, AUROC: 0.9374, ACC: 0.8606\n",
      "Train AUPRC: 0.8849, AUROC: 0.9483, ACC: 0.8606\n",
      "Train AUPRC: 0.8913, AUROC: 0.9494, ACC: 0.8245\n",
      "Train AUPRC: 0.8815, AUROC: 0.9474, ACC: 0.8865\n",
      "Train AUPRC: 0.8869, AUROC: 0.9483, ACC: 0.8981\n",
      "Train AUPRC: 0.8958, AUROC: 0.9501, ACC: 0.8852\n",
      "Epoch: 29, Train loss: 0.2788, Acc: 0.8836, Auprc: 0.8047, TP: 25, F1: 0.7463, Auroc: 0.9346\n",
      "Train AUPRC: 0.8978, AUROC: 0.9506, ACC: 0.8955\n",
      "Train AUPRC: 0.9013, AUROC: 0.9517, ACC: 0.8968\n",
      "Train AUPRC: 0.9005, AUROC: 0.9517, ACC: 0.8968\n",
      "Train AUPRC: 0.9082, AUROC: 0.9542, ACC: 0.9019\n",
      "Train AUPRC: 0.9118, AUROC: 0.9555, ACC: 0.8968\n",
      "Train AUPRC: 0.9138, AUROC: 0.9565, ACC: 0.8890\n",
      "Train AUPRC: 0.9101, AUROC: 0.9554, ACC: 0.8865\n",
      "Train AUPRC: 0.9188, AUROC: 0.9578, ACC: 0.8348\n",
      "Train AUPRC: 0.9154, AUROC: 0.9552, ACC: 0.8090\n",
      "Train AUPRC: 0.9121, AUROC: 0.9551, ACC: 0.8090\n",
      "Epoch: 39, Train loss: 0.3930, Acc: 0.7671, Auprc: 0.8776, TP: 25, F1: 0.5952, Auroc: 0.9393\n",
      "Train AUPRC: 0.9092, AUROC: 0.9553, ACC: 0.8258\n",
      "Train AUPRC: 0.9122, AUROC: 0.9567, ACC: 0.9045\n",
      "Train AUPRC: 0.9170, AUROC: 0.9571, ACC: 0.8813\n",
      "Train AUPRC: 0.9179, AUROC: 0.9574, ACC: 0.9019\n",
      "Train AUPRC: 0.9156, AUROC: 0.9570, ACC: 0.8387\n",
      "Train AUPRC: 0.9148, AUROC: 0.9569, ACC: 0.8335\n",
      "Train AUPRC: 0.9156, AUROC: 0.9572, ACC: 0.8813\n",
      "Train AUPRC: 0.9192, AUROC: 0.9582, ACC: 0.9045\n",
      "Train AUPRC: 0.9201, AUROC: 0.9585, ACC: 0.9058\n",
      "Train AUPRC: 0.9203, AUROC: 0.9587, ACC: 0.8994\n",
      "Epoch: 49, Train loss: 0.2269, Acc: 0.8973, Auprc: 0.8946, TP: 24, F1: 0.7619, Auroc: 0.9455\n",
      "Train AUPRC: 0.9214, AUROC: 0.9593, ACC: 0.8942\n",
      "Train AUPRC: 0.9214, AUROC: 0.9597, ACC: 0.8800\n",
      "Train AUPRC: 0.9229, AUROC: 0.9606, ACC: 0.9032\n",
      "Train AUPRC: 0.9206, AUROC: 0.9592, ACC: 0.8839\n",
      "Train AUPRC: 0.9225, AUROC: 0.9610, ACC: 0.8761\n",
      "Train AUPRC: 0.9183, AUROC: 0.9596, ACC: 0.8245\n",
      "Train AUPRC: 0.9192, AUROC: 0.9601, ACC: 0.8800\n",
      "Train AUPRC: 0.9212, AUROC: 0.9600, ACC: 0.8787\n",
      "Train AUPRC: 0.9204, AUROC: 0.9604, ACC: 0.9045\n",
      "Train AUPRC: 0.9129, AUROC: 0.9561, ACC: 0.8129\n",
      "Epoch: 59, Train loss: 0.3094, Acc: 0.7740, Auprc: 0.8568, TP: 25, F1: 0.6024, Auroc: 0.9353\n",
      "Train AUPRC: 0.9124, AUROC: 0.9557, ACC: 0.8129\n",
      "Train AUPRC: 0.9102, AUROC: 0.9551, ACC: 0.8619\n",
      "Train AUPRC: 0.9113, AUROC: 0.9552, ACC: 0.8787\n",
      "Train AUPRC: 0.9137, AUROC: 0.9559, ACC: 0.8942\n",
      "Train AUPRC: 0.9164, AUROC: 0.9571, ACC: 0.8994\n",
      "Train AUPRC: 0.9187, AUROC: 0.9580, ACC: 0.8981\n",
      "Train AUPRC: 0.9193, AUROC: 0.9585, ACC: 0.8942\n",
      "Train AUPRC: 0.9199, AUROC: 0.9589, ACC: 0.8826\n",
      "Train AUPRC: 0.9179, AUROC: 0.9588, ACC: 0.8968\n",
      "Train AUPRC: 0.9191, AUROC: 0.9600, ACC: 0.8981\n",
      "Epoch: 69, Train loss: 0.2814, Acc: 0.9178, Auprc: 0.8592, TP: 24, F1: 0.8000, Auroc: 0.9353\n",
      "Train AUPRC: 0.9224, AUROC: 0.9611, ACC: 0.9019\n",
      "Train AUPRC: 0.9265, AUROC: 0.9626, ACC: 0.9071\n",
      "Train AUPRC: 0.9280, AUROC: 0.9630, ACC: 0.9135\n",
      "Train AUPRC: 0.9279, AUROC: 0.9631, ACC: 0.8890\n",
      "Train AUPRC: 0.9302, AUROC: 0.9631, ACC: 0.8981\n",
      "Train AUPRC: 0.9293, AUROC: 0.9636, ACC: 0.9135\n",
      "Train AUPRC: 0.9272, AUROC: 0.9632, ACC: 0.8942\n",
      "Train AUPRC: 0.9277, AUROC: 0.9634, ACC: 0.9097\n",
      "Train AUPRC: 0.9257, AUROC: 0.9626, ACC: 0.9058\n",
      "Train AUPRC: 0.9206, AUROC: 0.9604, ACC: 0.8968\n",
      "Epoch: 79, Train loss: 0.2488, Acc: 0.9041, Auprc: 0.8705, TP: 24, F1: 0.7742, Auroc: 0.9374\n",
      "Train AUPRC: 0.9216, AUROC: 0.9609, ACC: 0.8968\n",
      "Train AUPRC: 0.9274, AUROC: 0.9630, ACC: 0.9071\n",
      "Train AUPRC: 0.9298, AUROC: 0.9639, ACC: 0.8968\n",
      "Train AUPRC: 0.9238, AUROC: 0.9616, ACC: 0.8787\n",
      "Train AUPRC: 0.9214, AUROC: 0.9604, ACC: 0.8452\n",
      "Train AUPRC: 0.9268, AUROC: 0.9630, ACC: 0.9084\n",
      "Train AUPRC: 0.9282, AUROC: 0.9635, ACC: 0.8942\n",
      "Train AUPRC: 0.9212, AUROC: 0.9604, ACC: 0.8929\n",
      "Train AUPRC: 0.9197, AUROC: 0.9599, ACC: 0.8929\n",
      "Train AUPRC: 0.9201, AUROC: 0.9598, ACC: 0.8955\n",
      "Epoch: 89, Train loss: 0.2539, Acc: 0.9247, Auprc: 0.9011, TP: 24, F1: 0.8136, Auroc: 0.9424\n",
      "Train AUPRC: 0.9228, AUROC: 0.9610, ACC: 0.9058\n",
      "Train AUPRC: 0.9265, AUROC: 0.9627, ACC: 0.9071\n",
      "Train AUPRC: 0.9292, AUROC: 0.9635, ACC: 0.9097\n",
      "Train AUPRC: 0.9303, AUROC: 0.9638, ACC: 0.9135\n",
      "Train AUPRC: 0.9302, AUROC: 0.9639, ACC: 0.9006\n",
      "Train AUPRC: 0.9321, AUROC: 0.9644, ACC: 0.9123\n",
      "Train AUPRC: 0.9328, AUROC: 0.9647, ACC: 0.9135\n",
      "Train AUPRC: 0.9322, AUROC: 0.9648, ACC: 0.9148\n",
      "Train AUPRC: 0.9299, AUROC: 0.9637, ACC: 0.8994\n",
      "Train AUPRC: 0.9299, AUROC: 0.9637, ACC: 0.8994\n",
      "Epoch: 99, Train loss: 0.2045, Acc: 0.9041, Auprc: 0.9038, TP: 24, F1: 0.7742, Auroc: 0.9424\n",
      "Train AUPRC: 0.9315, AUROC: 0.9643, ACC: 0.9123\n",
      "Train AUPRC: 0.9329, AUROC: 0.9649, ACC: 0.8994\n",
      "Train AUPRC: 0.9335, AUROC: 0.9648, ACC: 0.9110\n",
      "Train AUPRC: 0.9315, AUROC: 0.9635, ACC: 0.8400\n",
      "Train AUPRC: 0.9312, AUROC: 0.9636, ACC: 0.8748\n",
      "Train AUPRC: 0.9314, AUROC: 0.9638, ACC: 0.9135\n",
      "Train AUPRC: 0.9316, AUROC: 0.9640, ACC: 0.9084\n",
      "Train AUPRC: 0.9311, AUROC: 0.9640, ACC: 0.8994\n",
      "Train AUPRC: 0.9311, AUROC: 0.9638, ACC: 0.8877\n",
      "Train AUPRC: 0.9321, AUROC: 0.9638, ACC: 0.9110\n",
      "Epoch: 109, Train loss: 0.2503, Acc: 0.9110, Auprc: 0.9203, TP: 24, F1: 0.7869, Auroc: 0.9486\n",
      "Train AUPRC: 0.9325, AUROC: 0.9636, ACC: 0.9045\n",
      "Train AUPRC: 0.9321, AUROC: 0.9636, ACC: 0.9006\n",
      "Train AUPRC: 0.9323, AUROC: 0.9638, ACC: 0.9058\n",
      "Train AUPRC: 0.9318, AUROC: 0.9638, ACC: 0.9045\n",
      "Train AUPRC: 0.9326, AUROC: 0.9642, ACC: 0.9032\n",
      "Train AUPRC: 0.9334, AUROC: 0.9645, ACC: 0.8826\n",
      "Train AUPRC: 0.9327, AUROC: 0.9644, ACC: 0.9071\n",
      "Train AUPRC: 0.9316, AUROC: 0.9641, ACC: 0.8594\n",
      "Train AUPRC: 0.9347, AUROC: 0.9654, ACC: 0.9071\n",
      "Train AUPRC: 0.9364, AUROC: 0.9658, ACC: 0.9045\n",
      "Epoch: 119, Train loss: 0.2239, Acc: 0.9452, Auprc: 0.9201, TP: 23, F1: 0.8519, Auroc: 0.9474\n",
      "Train AUPRC: 0.9374, AUROC: 0.9661, ACC: 0.9135\n",
      "Train AUPRC: 0.9375, AUROC: 0.9664, ACC: 0.8994\n",
      "Train AUPRC: 0.9393, AUROC: 0.9670, ACC: 0.9019\n",
      "Train AUPRC: 0.9399, AUROC: 0.9674, ACC: 0.9123\n",
      "Train AUPRC: 0.9390, AUROC: 0.9673, ACC: 0.9071\n",
      "Train AUPRC: 0.9399, AUROC: 0.9675, ACC: 0.9123\n",
      "Train AUPRC: 0.9384, AUROC: 0.9670, ACC: 0.8968\n",
      "Train AUPRC: 0.9392, AUROC: 0.9674, ACC: 0.9019\n",
      "Train AUPRC: 0.9398, AUROC: 0.9675, ACC: 0.9135\n",
      "Train AUPRC: 0.9395, AUROC: 0.9672, ACC: 0.9084\n",
      "Epoch: 129, Train loss: 0.2056, Acc: 0.9247, Auprc: 0.8880, TP: 22, F1: 0.8000, Auroc: 0.9399\n",
      "Train AUPRC: 0.9401, AUROC: 0.9676, ACC: 0.9187\n",
      "Train AUPRC: 0.9406, AUROC: 0.9679, ACC: 0.9123\n",
      "Train AUPRC: 0.9411, AUROC: 0.9682, ACC: 0.9097\n",
      "Train AUPRC: 0.9400, AUROC: 0.9676, ACC: 0.8994\n",
      "Train AUPRC: 0.9415, AUROC: 0.9683, ACC: 0.9110\n",
      "Train AUPRC: 0.9419, AUROC: 0.9686, ACC: 0.9161\n",
      "Train AUPRC: 0.9422, AUROC: 0.9686, ACC: 0.9148\n",
      "Train AUPRC: 0.9438, AUROC: 0.9691, ACC: 0.9187\n",
      "Train AUPRC: 0.9451, AUROC: 0.9694, ACC: 0.9148\n",
      "Train AUPRC: 0.9447, AUROC: 0.9691, ACC: 0.9084\n",
      "Epoch: 139, Train loss: 0.3504, Acc: 0.9247, Auprc: 0.8970, TP: 22, F1: 0.8000, Auroc: 0.9443\n",
      "Train AUPRC: 0.9406, AUROC: 0.9669, ACC: 0.8890\n",
      "Train AUPRC: 0.9448, AUROC: 0.9691, ACC: 0.9135\n",
      "Train AUPRC: 0.9427, AUROC: 0.9686, ACC: 0.9045\n",
      "Train AUPRC: 0.9412, AUROC: 0.9682, ACC: 0.9032\n",
      "Train AUPRC: 0.9430, AUROC: 0.9689, ACC: 0.9161\n",
      "Train AUPRC: 0.9435, AUROC: 0.9691, ACC: 0.9187\n",
      "Train AUPRC: 0.9394, AUROC: 0.9676, ACC: 0.9019\n",
      "Train AUPRC: 0.9376, AUROC: 0.9668, ACC: 0.8929\n",
      "Train AUPRC: 0.9395, AUROC: 0.9674, ACC: 0.9084\n",
      "Train AUPRC: 0.9431, AUROC: 0.9693, ACC: 0.9097\n",
      "Epoch: 149, Train loss: 0.2092, Acc: 0.9452, Auprc: 0.9118, TP: 23, F1: 0.8519, Auroc: 0.9518\n",
      "Train AUPRC: 0.9442, AUROC: 0.9697, ACC: 0.9123\n",
      "Train AUPRC: 0.9435, AUROC: 0.9689, ACC: 0.9071\n",
      "Train AUPRC: 0.9403, AUROC: 0.9677, ACC: 0.8671\n",
      "Train AUPRC: 0.9436, AUROC: 0.9686, ACC: 0.9045\n",
      "Train AUPRC: 0.9429, AUROC: 0.9676, ACC: 0.9032\n",
      "Train AUPRC: 0.9355, AUROC: 0.9643, ACC: 0.8916\n",
      "Train AUPRC: 0.9282, AUROC: 0.9598, ACC: 0.8245\n",
      "Train AUPRC: 0.9390, AUROC: 0.9660, ACC: 0.8271\n",
      "Train AUPRC: 0.9438, AUROC: 0.9687, ACC: 0.9097\n",
      "Train AUPRC: 0.9428, AUROC: 0.9684, ACC: 0.9200\n",
      "Epoch: 159, Train loss: 0.2639, Acc: 0.9247, Auprc: 0.9167, TP: 24, F1: 0.8136, Auroc: 0.9527\n",
      "Train AUPRC: 0.9416, AUROC: 0.9684, ACC: 0.9174\n",
      "Train AUPRC: 0.9407, AUROC: 0.9685, ACC: 0.9148\n",
      "Train AUPRC: 0.9424, AUROC: 0.9693, ACC: 0.9174\n",
      "Train AUPRC: 0.9439, AUROC: 0.9700, ACC: 0.9213\n",
      "Train AUPRC: 0.9427, AUROC: 0.9694, ACC: 0.9187\n",
      "Train AUPRC: 0.9379, AUROC: 0.9671, ACC: 0.8994\n",
      "Train AUPRC: 0.9381, AUROC: 0.9671, ACC: 0.8968\n",
      "Train AUPRC: 0.9418, AUROC: 0.9686, ACC: 0.9110\n",
      "Train AUPRC: 0.9450, AUROC: 0.9699, ACC: 0.9213\n",
      "Train AUPRC: 0.9473, AUROC: 0.9707, ACC: 0.9265\n",
      "Epoch: 169, Train loss: 0.2517, Acc: 0.9247, Auprc: 0.9191, TP: 24, F1: 0.8136, Auroc: 0.9527\n",
      "Train AUPRC: 0.9486, AUROC: 0.9712, ACC: 0.9148\n",
      "Train AUPRC: 0.9493, AUROC: 0.9714, ACC: 0.9161\n",
      "Train AUPRC: 0.9493, AUROC: 0.9715, ACC: 0.9135\n",
      "Train AUPRC: 0.9492, AUROC: 0.9717, ACC: 0.9097\n",
      "Train AUPRC: 0.9470, AUROC: 0.9701, ACC: 0.8903\n",
      "Train AUPRC: 0.9476, AUROC: 0.9701, ACC: 0.8994\n",
      "Train AUPRC: 0.9474, AUROC: 0.9699, ACC: 0.9213\n",
      "Train AUPRC: 0.9480, AUROC: 0.9701, ACC: 0.9135\n",
      "Train AUPRC: 0.9500, AUROC: 0.9709, ACC: 0.9226\n",
      "Train AUPRC: 0.9517, AUROC: 0.9717, ACC: 0.9006\n",
      "Epoch: 179, Train loss: 0.2695, Acc: 0.8973, Auprc: 0.8997, TP: 24, F1: 0.7619, Auroc: 0.9424\n",
      "Train AUPRC: 0.9517, AUROC: 0.9722, ACC: 0.9213\n",
      "Train AUPRC: 0.9524, AUROC: 0.9729, ACC: 0.9239\n",
      "Train AUPRC: 0.9538, AUROC: 0.9736, ACC: 0.9290\n",
      "Train AUPRC: 0.9542, AUROC: 0.9739, ACC: 0.9303\n",
      "Train AUPRC: 0.9538, AUROC: 0.9739, ACC: 0.9252\n",
      "Train AUPRC: 0.9549, AUROC: 0.9739, ACC: 0.9303\n",
      "Train AUPRC: 0.9553, AUROC: 0.9740, ACC: 0.9148\n",
      "Train AUPRC: 0.9548, AUROC: 0.9739, ACC: 0.9303\n",
      "Train AUPRC: 0.9537, AUROC: 0.9735, ACC: 0.9084\n",
      "Train AUPRC: 0.9543, AUROC: 0.9737, ACC: 0.9303\n",
      "Epoch: 189, Train loss: 0.2355, Acc: 0.9110, Auprc: 0.9082, TP: 22, F1: 0.7719, Auroc: 0.9477\n",
      "Train AUPRC: 0.9541, AUROC: 0.9737, ACC: 0.9110\n",
      "Train AUPRC: 0.9546, AUROC: 0.9739, ACC: 0.9071\n",
      "Train AUPRC: 0.9551, AUROC: 0.9743, ACC: 0.9226\n",
      "Train AUPRC: 0.9554, AUROC: 0.9745, ACC: 0.9329\n",
      "Train AUPRC: 0.9553, AUROC: 0.9745, ACC: 0.9239\n",
      "Train AUPRC: 0.9553, AUROC: 0.9745, ACC: 0.9135\n",
      "Train AUPRC: 0.9557, AUROC: 0.9746, ACC: 0.9226\n",
      "Train AUPRC: 0.9536, AUROC: 0.9735, ACC: 0.9239\n"
     ]
    }
   ],
   "source": [
    "from data_preprocess_cv import get_data\n",
    "from main import get_training_modules, train_model, predict, calculate_metrics, pred_to_df, score_avg_perfomance\n",
    "\n",
    "# To load dataset from above, set\n",
    "# configs['stable'] = False\n",
    "# To use a stable version in the repo, set\n",
    "configs['stable'] = True\n",
    "# The two version should be the same by a consistent process.\n",
    "\n",
    "# Set a GPU with enough memory\n",
    "gpu = 3\n",
    "configs[\"gpu\"] = f\"cuda:{gpu}\"\n",
    "\n",
    "# Set log_name and logfile to suit your needs, and you will see training details in logfile.\n",
    "configs['log_name'] = f\"{get_cell_line(configs['data_dir'])[1:]}_{configs['ppi']}\"\n",
    "configs['logfile'] = os.path.join(configs[\"log_dir\"], configs[\"log_name\"] + \".txt\")\n",
    "\n",
    "dataset = get_data(configs=configs, stable=configs['stable'])\n",
    "\n",
    "sum_auprc, sum_auc, sum_acc, sum_f1, sum_tp, train_result = [], [], [], [], [], []\n",
    "for i in range(CV_FOLDS):\n",
    "    head_info = True if i == 0 else False\n",
    "    configs['fold'] = i\n",
    "    modules = get_training_modules(configs, dataset)\n",
    "    auprc, auc, acc, f1, tp, new_ckpt = train_model(modules, configs, configs['log_name'], i, head_info,)\n",
    "    sum_auprc.append(auprc)\n",
    "    sum_auc.append(auc)\n",
    "    sum_acc.append(acc)\n",
    "    sum_f1.append(f1)\n",
    "    sum_tp.append(tp)\n",
    "    y_score, y_pred, y_true, y_index = predict(modules['model'], modules['test_loader_list'], configs, new_ckpt)\n",
    "    acc, cf_matrix, auprc, f1, auc = calculate_metrics(y_true, y_pred, y_score)\n",
    "    tp = cf_matrix[1, 1]\n",
    "    with open(configs['logfile'], 'a') as f:\n",
    "        print(\"Test AUPRC:{:.4f}, AUROC:{:.4f}, ACC:{:.4f}, F1:{:.4f}, TP:{:.1f}\"\n",
    "            .format(auprc, auc, acc, f1, tp), file=f, flush=True)\n",
    "    train_result =  pred_to_df(i, train_result, y_index, y_true, y_score)\n",
    "score_col = [f\"score_{i}\" for i in range(CV_FOLDS)]\n",
    "train_result['avg_score'] = train_result[score_col].mean(axis=1)\n",
    "train_result['pred_label'] = train_result.apply(\n",
    "    lambda x: 1 if x['avg_score'] > 0.5 else 0, axis=1)\n",
    "score_avg_perfomance(train_result, score_col, configs['logfile'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neoloop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
